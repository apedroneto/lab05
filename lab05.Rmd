---
title: "Lab05"
author: "Antonio Pedro de Abreu Neto"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(caret)
library(ROSE)
library(rpart)
```

## Lendo os dados de treino e teste
```{r}
input <- read.csv("data/train.csv")
#test_data <- read.csv("test.csv")
```

## Removendo variáveis categóricas dos dados de treino, pois são irrelevantes para a regressão
```{r}
input <- input %>% select(-nome, -uf, -estado_civil, 
                          -partido, -ocupacao,-ano, 
                          -cargo,-grau,-sexo, 
                          -sequencial_candidato)
```

```{r}
dataPartition <- createDataPartition(y = input$situacao, p=0.75, list=FALSE)
set.seed(9560)
## separando o dataframe em treino e teste
train_data <- input[dataPartition, ]
test_data <- input[-dataPartition, ]
```

## 1º Questão
#Há desbalanceamento das classes (isto é, uma classe tem muito mais instâncias que outra)? Em que proporção? Quais efeitos #colaterais o desbalanceamento de classes pode causar no classificador? Como você poderia tratar isso? (10 pt.)

```{r}
input %>% group_by(situacao) %>%
  summarise(p_eleitos=(n()/nrow(input)*100)) %>% ggplot(aes(x=situacao, y=p_eleitos, fill=situacao)) + geom_col()
```

Existe um desbalanceamento entre as classes eleito e nao_eleito, tendo a classe nao_eleito com muito mais instâncias que a eleito, o efeito colateral será uma tendencia a situação não eleito.

```{r}
train_data <- train_data %>% select(-recursos_de_outros_candidatos.comites, -recursos_de_partido_politico, -recursos_de_pessoas_fisicas, -recursos_de_pessoas_juridicas, -recursos_proprios)


rose_train <- ROSE(situacao ~ ., data  = train_data)$data  

table(rose_train$situacao) 
up_train <- upSample(x = train_data[,],
                     y = train_data$situacao)  
up_train <- up_train %>% select(-Class)
table(up_train$situacao) 
down_train <- downSample(x = train_data[, -ncol(train_data)],
                         y = train_data$situacao)
down_train <- down_train %>% select(-Class)
table(down_train$situacaO)  
```

O método escolhido será o ROSE, que tanto cria instâncias da classe minoritária quanto diminui instâncias da classe majoritária.


## Treine: um modelo de KNN, regressão logística, uma árvore de decisão e um modelo de adaboost. Tune esses modelos usando validação cruzada e controle overfitting se necessário, considerando as particularidades de cada modelo.  (20 pts.)
```{r}
# usando validação cruzada 10-fold com 5 repetições
fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 5,
                           classProbs = TRUE)
```

Regressão Logística

```{r warning=FALSE}
reg_logistica <- glm(formula=situacao~., data = rose_train, family=binomial)

plot(reg_logistica)
```

Árvore de decisão

```{r}
arvore <- train(
    x = rose_train[, names(rose_train) != "situacao"],
    y = rose_train$situacao,
    method = "rpart",
    trControl = fitControl,
    control = rpart.control(cp = 0.4))

plot(arvore)
```

Adaboost

```{r}
adaboost <- train(x = rose_train[, names(rose_train) != "situacao"],
                y = rose_train$situacao,
                method = "adaboost",
                trControl = fitControl)
```

KNN
```{r} 
k <- expand.grid(k = seq(20, 100, length=81))
modelo_knn <- train(situacao ~ ., data = input, 
                   method = "knn", 
                   tuneGrid = k, 
                   preProc = c("center", "scale"), 
                   trControl = fitControl)
modelo_knn
```

##Reporte precision, recall e f-measure no treino e validação. Há uma grande diferença de desempenho no treino/validação? Como você avalia os resultados? Justifique sua resposta. (10 pt.)



## Interprete as saídas dos modelos. Quais atributos parecem ser mais importantes de acordo com cada modelo? (20 pts.)

```{r}

varImp(arvore)
varImp(adaboost)
varImp(modelo_knn)
varImp(reg_logistica)

```

No KNN os atributos com maior peso são:
      quantidade_fornecedores,
      recursos_de_pessoas_juridicas,
      quantidade_doadores,
      quantidade_despesas,
      total_despesas.

Na arvore os atributos com maior peso foram:
      total_despesa,
      quantidade_fornecedores,
      total_receita.

No adaboost o atributo os pessos ficaram em: total_despesa está entre um dos maiores junto com total_receita

Na regressão logística os atributos com maior peso estão entre: 
      media_receita,
      media_despesa,
      quantidade_doadores.

##Envie seus melhores modelos à competição do Kaggle. Faça pelo menos uma submissão. Sugestões para melhorar o modelo: (20 pts.)
## - Experimente outros modelos (e.g. SVM, RandomForests e GradientBoosting).
## - Experimente balancear as classes,  caso estejam desbalanceadas.
## - Experimente outras estratégias de ensembles (e.g. Stacking)

```{r}
prediction <- predict(knn_model, test_data)  
data_out <- data.frame(ID = test_data$sequencial_candidato, Predicted = prediction) 
data_out$ID <-as.character(data_out$ID)  
data_out %>% write_csv(path = "arquivo.csv") 
```
