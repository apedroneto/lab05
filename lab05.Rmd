---
title: "Lab05"
author: "Antonio Pedro de Abreu Neto"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(caret)
library(ROSE)
library(rpart)
```

## Lendo os dados de treino e teste
```{r}
input <- read.csv("data/train.csv")
#test_data <- read.csv("test.csv")
```

## Removendo variáveis categóricas dos dados de treino, pois são irrelevantes para a regressão
```{r}
input <- input %>% select(-nome, -uf, -estado_civil, 
                          -partido, -ocupacao,-ano, 
                          -cargo,-grau,-sexo, 
                          -sequencial_candidato)
```

```{r}
dataPartition <- createDataPartition(y = input$situacao, p=0.75, list=FALSE)
set.seed(9560)
## separando o dataframe em treino e teste
train_data <- input[dataPartition, ]
test_data <- input[-dataPartition, ]
```

## 1º Questão
#Há desbalanceamento das classes (isto é, uma classe tem muito mais instâncias que outra)? Em que proporção? Quais efeitos #colaterais o desbalanceamento de classes pode causar no classificador? Como você poderia tratar isso? (10 pt.)

```{r}
input %>% group_by(situacao) %>%
  summarise(p_eleitos=(n()/nrow(input)*100)) %>% ggplot(aes(x=situacao, y=p_eleitos, fill=situacao)) + geom_col()
```

Existe um desbalanceamento entre as classes eleito e nao_eleito, tendo a classe nao_eleito com muito mais instâncias que a eleito, o efeito colateral será uma tendencia a situação não eleito.

```{r}
train_data <- train_data %>% select(-recursos_de_outros_candidatos.comites, -recursos_de_partido_politico, -recursos_de_pessoas_fisicas, -recursos_de_pessoas_juridicas, -recursos_proprios)


rose_train <- ROSE(situacao ~ ., data  = train_data)$data  

table(rose_train$situacao) 
up_train <- upSample(x = train_data[,],
                     y = train_data$situacao)  
up_train <- up_train %>% select(-Class)
table(up_train$situacao) 
down_train <- downSample(x = train_data[, -ncol(train_data)],
                         y = train_data$situacao)
down_train <- down_train %>% select(-Class)
table(down_train$situacaO)  
```

O método escolhido será o ROSE, que tanto cria instâncias da classe minoritária quanto diminui instâncias da classe majoritária.


## Second question
```{r}
# usando validação cruzada 10-fold com 5 repetições
fitControl <- trainControl(method = "repeatedcv",
                           number = 10,
                           repeats = 5,
                           classProbs = TRUE)
```

Regressão Logística

```{r warning=FALSE}
reg_logistica <- glm(formula=situacao~., data = rose_train, family=binomial)

plot(reg_logistica)
```

Árvore de decisão

```{r}
arvore <- train(
    x = rose_train[, names(rose_train) != "situacao"],
    y = rose_train$situacao,
    method = "rpart",
    trControl = fitControl,
    control = rpart.control(cp = 0.4))

plot(arvore)
```

Adaboost

```{r}
adaboost <- train(x = rose_train[, names(rose_train) != "situacao"],
                y = rose_train$situacao,
                method = "adaboost",
                trControl = fitControl)
```

KNN
```{r} 
k <- expand.grid(k = seq(20, 100, length=81)) knn_model <- train(situacao ~ .,                     data = input,                     method = "knn",                     tuneGrid = k,                     preProc = c("center", "scale"),                     trControl = fitControl)  plot(knn_model) 
```

